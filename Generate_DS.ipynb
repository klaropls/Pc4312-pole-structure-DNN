{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2157564-6710-487e-9bd0-098de3ea8306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from final_pole_module.ipynb\n",
      "Number of poles to be generated per class: 4000000\n",
      "Ndata to be generated= 16000000\n",
      "Your directory is: curriculum20_training\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cmath as cm\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import chainer\n",
    "from chainer import configuration\n",
    "from chainer.dataset import convert\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Import the module containing the class pole\n",
    "import import_ipynb\n",
    "import final_pole_module\n",
    "from final_pole_module import detect_cusp, unif_pole, T1, T2, Einput\n",
    "from final_pole_module import mu1, mu2, T1, T2, T4, Nreal, Nimag, hbarc, seerealimagpart\n",
    "from final_pole_module import Einput, Ereal, Eimag, Erealfar, Eimagfar, E_exp, labelz, inspect, NEpoints\n",
    "from final_pole_module import skip_duplicate, export_data, import_data, get_traintest, directory\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdd88db-4817-4045-bde0-58563b44fa0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 6400\n",
      "Size of testing dataset: 1600\n",
      "Test output values: [ 0  1 11 21]\n",
      "Test output value counts: [400 400 400 400]\n",
      "Size of training dataset: 8000\n",
      "Size of testing dataset: 2000\n",
      "Test output values: [ 0  1  2 11 21]\n",
      "Test output value counts: [400 400 400 400 400]\n",
      "Size of training dataset: 9600\n",
      "Size of testing dataset: 2400\n",
      "Test output values: [ 0  1  2 11 12 21]\n",
      "Test output value counts: [400 400 400 400 400 400]\n",
      "Size of training dataset: 11200\n",
      "Size of testing dataset: 2800\n",
      "Test output values: [ 0  1  2 11 12 21 22]\n",
      "Test output value counts: [400 400 400 400 400 400 400]\n",
      "Size of training dataset: 12800\n",
      "Size of testing dataset: 3200\n",
      "Test output values: [ 0  1  2 10 11 12 21 22]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 14400\n",
      "Size of testing dataset: 3600\n",
      "Test output values: [ 0  1  2 10 11 12 20 21 22]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 16000\n",
      "Size of testing dataset: 4000\n",
      "Test output values: [ 0  1  2 10 11 12 20 21 22 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 17600\n",
      "Size of testing dataset: 4400\n",
      "Test output values: [ 0  1  2  6 10 11 12 20 21 22 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 19200\n",
      "Size of testing dataset: 4800\n",
      "Test output values: [ 0  1  2  6  8 10 11 12 20 21 22 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 20800\n",
      "Size of testing dataset: 5200\n",
      "Test output values: [ 0  1  2  6  8 10 11 12 16 20 21 22 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 22400\n",
      "Size of testing dataset: 5600\n",
      "Test output values: [ 0  1  2  6  8 10 11 12 16 18 20 21 22 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 24000\n",
      "Size of testing dataset: 6000\n",
      "Test output values: [ 0  1  2  6  8 10 11 12 16 18 20 21 22 26 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 25600\n",
      "Size of testing dataset: 6400\n",
      "Test output values: [ 0  1  2  6  8 10 11 12 16 18 20 21 22 26 28 30]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 27200\n",
      "Size of testing dataset: 6800\n",
      "Test output values: [ 0  1  2  6  8 10 11 12 16 18 20 21 22 26 28 30 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 28800\n",
      "Size of testing dataset: 7200\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 16 18 20 21 22 26 28 30 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400]\n",
      "Size of training dataset: 30400\n",
      "Size of testing dataset: 7600\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 15 16 18 20 21 22 26 28 30 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400\n",
      " 400]\n",
      "Size of training dataset: 32000\n",
      "Size of testing dataset: 8000\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 15 16 17 18 20 21 22 26 28 30 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400\n",
      " 400 400]\n",
      "Size of training dataset: 33600\n",
      "Size of testing dataset: 8400\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 15 16 17 18 20 21 22 26 27 28 30 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400\n",
      " 400 400 400]\n",
      "Size of training dataset: 35200\n",
      "Size of testing dataset: 8800\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 15 16 17 18 20 21 22 26 27 28 30 31 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400\n",
      " 400 400 400 400]\n",
      "Size of training dataset: 36800\n",
      "Size of testing dataset: 9200\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 15 16 17 18 20 21 22 26 27 28 30 31 32 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400\n",
      " 400 400 400 400 400]\n",
      "Size of training dataset: 38400\n",
      "Size of testing dataset: 9600\n",
      "Test output values: [ 0  1  2  6  7  8 10 11 12 15 16 17 18 20 21 22 26 27 28 30 31 32 33 34]\n",
      "Test output value counts: [400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400 400\n",
      " 400 400 400 400 400 400]\n"
     ]
    }
   ],
   "source": [
    "for XX in range(1, 22): #33\n",
    "    directory = f'curriculum{XX:02d}_training'\n",
    "    get_traintest(directory, XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a4cbb-e3b9-44fa-9d3e-9b9b75c5c6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
